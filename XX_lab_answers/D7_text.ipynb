{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7d3dafa230af1af",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Text Analysis\n",
    "\n",
    "In this lab we'll do a short text analysis so that you start to become familiar with the packages and tools available to you in Python to work with text data. Nothing here will be very in-depth - it's supposed to be able to be completed in a short period of time after all. But, it will give you a starting point for your final assignment and projects, should you want to analyze text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab7cad2d5d781d48",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Data Science Question\n",
    "In this short project, we're going to answer the question: *For each presidential inauguration, which word is most unique?* \n",
    "\n",
    "To do this, we'll use the text from each Inaugural address in American history and carry out a TF-IDF analaysis.\n",
    "\n",
    "Secondarily, we'll think about whether these words make sense in the context of the history at the time and visualize words uniqueness over the course of history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6def326b354bf91",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part I : Setup & Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0adbfeb986a31274",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This lab uses a number of different functions across multiple packages. **Run the following code cell and take a look at each package we'll be using below. Make sure you understand what the package is used for. Be sure to familiarize yourself with anything that you're not yet familiar with.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import nltk package \n",
    "# NLTK provides support for a wide variety of text processing tasks: \n",
    "# tokenization, stemming, proper name identification, part of speech identification, etc. \n",
    "#   PennTreeBank word tokenizer \n",
    "#   English language stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# scikit-learn imports\n",
    "#   TF-IDF Vectorizer that first removes widely used words in the dataset and then transforms test data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# import re for regular expression\n",
    "import re\n",
    "\n",
    "## seaborn for plotting\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2, style=\"white\")\n",
    "\n",
    "# import matplotlib for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# set plotting size parameter\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "# improve resolution\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db67b6ab3ff028c6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To get started on your text analysis using the `nltk` package, run the code below to **download the NLTK English tokenizer ('punkt'), stopwords of all languages ('stopwords') from `nltk`, and the inaugural dataset from `nltk` ('inaugural')**. To determine what code you'll need to do this, you can explore the `download` method [here](https://www.nltk.org/) or their book [here](http://www.nltk.org/book/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad5ce2ec5ce7d4af",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('inaugural')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7443ebf7f9e7dc56",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that you have downloaded a few of the datasets you'll need, **import the `inaugural` dataset from `nltk.corpus`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c25d2300264c1f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from nltk.corpus import inaugural\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-df848beec787864c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f3ffc530ee1a4a55",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If all is working well, the following cell should display the files included in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd6127723bcdc17d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91f276f62e3d3658",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As you can see there is one file from each address. And, you'll note that the filename includes the year of each address. We'll want to use that address later, so **write code that extracts each year from the filename and stores it as a list. Assign this list to the variable `years`.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8c35b3a8d165962",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "years = [fileid[:4] for fileid in inaugural.fileids()]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dba761f98cf172ae",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(years) == len(inaugural.fileids())\n",
    "assert years[1] == '1793'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76be36ec8ebfd3be",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's take a look at one of these addresses. We'll pick a short one - Washington's *second* address. **Run the code below to take a look.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdd5c90b100ac14c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# see Washington's Second Inaugural Address\n",
    "inaugural.raw('1793-Washington.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e10ca8d112c1c216",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You'll notice that there are some new line characters, as well as a colon, some commas, some periods. We're really only interested in the words though for TF-IDF, so let's remove all punctuation. **Write code that returns a list (`text`), where each element in the list includes the text as above, but with:\n",
    "- punctuation removed \n",
    "- each word separated by a space\n",
    "- all words are lower case (i.e. \"Constitution\" should be \"constitution)\n",
    "\n",
    "Assign this to the variable `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a2c6d6fc38b0acd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "text = [re.sub(r'[^A-Za-z0-9]+', ' ', x) for x in [inaugural.raw(file_id) for file_id in inaugural.fileids()]]\n",
    "text = list(map(str.lower, text))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dc70d907b5789bed",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(text, list)\n",
    "assert len(text) == 58\n",
    "out = re.search('^fellow',text[0])\n",
    "assert out != None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1154448bde27c653",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If you've done this correctly and you **run the following cell, all punctuation should be stripped from the text, so that you only see the words from Washington's second address, separated by spaces, with all words lowercase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18bd2aae55ec3725",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66f13e717de0d1c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "With that, you now have a dataset ready for analysis by TF-IDF!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bf8534e57d52fce",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part II : Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fdffd7def7829489",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To get started on your TF-IDF analysis, you'll first want to **create a `TfidfVectorizer` object to transform your text data into vectors. Assign this `TfidfVectorizer` object to `tfidf`.**\n",
    "\n",
    "In this object, you'll need to **pass five arguments to initialize `tfidf`**: \n",
    "* set to apply TF scaling: `sublinear_tf=True`\n",
    "* analyze at the word-level: `analyzer='word'`\n",
    "* set maximum number of unique words: ` max_features=2000`\n",
    "* specify that you want to tokenize the data using the word_tokenizer from NLTK: `tokenizer=word_tokenize`\n",
    "* remove English language stop words: `stop_words=stopwords.words(\"english\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-33b91ae24ac3ec7d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True,\n",
    "                        analyzer='word',\n",
    "                        max_features=2000,\n",
    "                        tokenizer=word_tokenize,\n",
    "                        stop_words=stopwords.words(\"english\"))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2fd89e1e4135ac38",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tfidf.analyzer == 'word'\n",
    "assert tfidf.max_features == 2000\n",
    "assert tfidf.tokenizer == word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f71715b9480eb1f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now, it's time to calculate TF-IDF for words across our corpus of Inaugural addresses! \n",
    "\n",
    "To do this:\n",
    "\n",
    "1. generate a DataFrame `inaug_tfidf` using the `tfidf.fit_transform` function to calculate TF-IDF on your `text` variable. \n",
    "2. Be sure that your index here is the year of the address and the columns are named with the columns of the words the values represent. The `get_feature_names` method from `tfidf` may help you accomplish the columns name assignment. And the `years` you created earlier may help you with the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-02461e46f376ab9b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "inaug_tfidf = pd.DataFrame(tfidf.fit_transform(text).toarray())\n",
    "inaug_tfidf.columns = tfidf.get_feature_names()\n",
    "inaug_tfidf.index = years\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b24052773747528",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(inaug_tfidf.index) == len(years)\n",
    "assert len(inaug_tfidf.columns) == 2000\n",
    "assert inaug_tfidf.shape == (58, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac1707808d9891ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29590e1aff297b9f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We're almost there. We now have a DataFrame that includes the TF-IDF for the top 2000 words in our corpus! **Now, you'll want to extract the single most unique word from each address. Assign this information (most likely a Series object) to the variable `most_unique`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85c21b394a6f9ea1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "most_unique = inaug_tfidf.idxmax(axis=1)\n",
    "### END SOLUTION\n",
    "most_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b2d1c19fc1ed79d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Take a look through this list of most unique words over time. Do they make sense based on what you know about American history? Do any surprise you?\n",
    "\n",
    "With that part of our Analysis done, one thing that stuck out to me in this list is the fact that \"british\" was the most unique word to the 1813 inaugural address. This made sense to me - it was early in American history and we had only recently left British rule. But, I was curious to see whether or not 'british' would show up uniquely (albeit less uniquely) in any later addresses. **Generate a line plot that plots the TF-IDF for the word \"british\" on the y-axis. Plot year on the x-axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf04bf8b6004eb21",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "x = inaug_tfidf.index\n",
    "plt.plot(x, inaug_tfidf['british'], label=\"british\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('TF-IDF')\n",
    "plt.xticks(np.arange(0,56,step=5))\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbbe87869aea0ea8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Here you should see that over time \"british\" peaked in inaugural addresses at a few interesting points throughout history. What about some other words?\n",
    "\n",
    "Using a similar approach, **plot TF-IDF for \"british\", \"america\", \"war\", and \"jobs\". Take a look at the trends over time. Feel free to look at other words' trends over time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17185d3b85abfe7f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plt.plot(x, inaug_tfidf['british'], label=\"british\")\n",
    "plt.plot(x, inaug_tfidf['america'], label=\"america\")\n",
    "plt.plot(x, inaug_tfidf['war'], label=\"war\")\n",
    "plt.plot(x, inaug_tfidf['jobs'], label=\"jobs\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('TF-IDF')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(np.arange(0,56,step=5))\n",
    "plt.show();\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ed15dc929006d89",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You should see that the mention of \"america\" happened frequently in the country's infancy, but then became less common, whereas \"british was really common early on and \"jobs\" has really only become applicable in recent innaugural addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be11e4ed9fa207f1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As with all analysis, TF-IDF is not without its limitations. Let's take a look at how our results change if we change the `max_features` result in our analysis above to include 4000 words (rather than 2000). **Redo the analysis to 1) calculate TF-IDF for these 4000 words, 2) identify the word with the highest TF-IDF in each year (assignt his to `most_unique_4000`, and 3) generate a dataframe with the most common word from each analysis.Then, take a look to see how changing one argument in your analysis can affect your results! Finally, you can regenerate line plots if you're interseted to see how your plots have changed in this new analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c3903c7bbcbecea6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define tfidfvectorizer object \n",
    "### BEGIN SOLUTION\n",
    "tfidf2 = TfidfVectorizer(sublinear_tf=True,\n",
    "                         analyzer='word',\n",
    "                         max_features=4000,\n",
    "                         tokenizer=word_tokenize,\n",
    "                         stop_words=stopwords.words(\"english\"))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-325533e85301c4df",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# calculate TF-DF on input text\n",
    "### BEGIN SOLUTION\n",
    "inaug_tfidf2 = pd.DataFrame(tfidf2.fit_transform(text).toarray())\n",
    "inaug_tfidf2.columns = tfidf2.get_feature_names()\n",
    "inaug_tfidf2.index = years \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ad72899d05312a9a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# identify most uniuqe word each year from new model\n",
    "### BEGIN SOLUTION\n",
    "most_unique_4000 = inaug_tfidf2.idxmax(axis=1)\n",
    "most_unique_4000\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0e45e7cb67f8de7d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# join most_unique from original model with this new list\n",
    "# in a single dataframe to compare word each year\n",
    "### BEGIN SOLUTION\n",
    "pd.concat([most_unique, most_unique_4000],axis=1)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cfdb2a2308535396",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regenerate plot\n",
    "### BEGIN SOLUTION\n",
    "#import datetime\n",
    "x = inaug_tfidf2.index\n",
    "plt.plot(x, inaug_tfidf2['british'], label=\"british\")\n",
    "plt.plot(x, inaug_tfidf2['america'], label=\"america\")\n",
    "plt.plot(x, inaug_tfidf2['war'], label=\"war\")\n",
    "plt.plot(x, inaug_tfidf2['jobs'], label=\"jobs\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(np.arange(0,56,step=5))\n",
    "plt.show();\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f1c57aaa1e86ead",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Good work getting comfortable working with text data here...and hopefully learning a bit more about Inaugural Addresses over time. Go ahead and submit your discussion lab!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
