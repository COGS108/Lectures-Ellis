{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dimensionality Reduction \n",
    "\n",
    "- General Overview\n",
    "- Examples with data:\n",
    "    - Iris Dataset\n",
    "    - S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "#improve resolution\n",
    "#comment this line if erroring on your machine/screen\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Code here in intro example adapted from Jake VanderPlas' [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# generate data and look at relationhip\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can tell that there is a linear relationship between the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Carry Out PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use PCA from sklearn\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# PCs\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Variance Explained\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualizing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To see what these numbers mean, let's visualize them:\n",
    "- as vectors over the input data\n",
    "    - using the \"components\" to define the direction of the vector\n",
    "    - and the \"explained variance\" to define the squared-length of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# generate draw_vector fucntion\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops = dict(arrowstyle='->',\n",
    "                      linewidth=2,\n",
    "                      shrinkA=0, \n",
    "                      shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.4)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Vectors represent the **principal axes** of the data\n",
    "- length of the vector = an indication of how \"important\" that axis is in describing the distribution of the dataâ€”more precisely:\n",
    "    - a measure of the variance of the data when projected onto that axis\n",
    "    - The projection of each data point onto the principal axes are the \"principal components\" of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA: Iris Dataset\n",
    "\n",
    "- Dataset\n",
    "- PCA\n",
    "- Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This example comes from plotly, but has been reproduced in many places, as the iris dataset is quite famous: https://plot.ly/ipython-notebooks/principal-component-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read dataset in\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "                 header=None)\n",
    "\n",
    "# change column names and drop empty line\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "df['species'] = df['class'].replace(to_replace = \"Iris-\", value = \"\", regex=True)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# boxplot across variables\n",
    "df.boxplot(by='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A) setosa and versicolor\n",
    "- B) setosa and virginica\n",
    "- C) versicolor and viginica\n",
    "- D) all quite distinct\n",
    "- E) all equally similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot two variables\n",
    "sns.scatterplot(x='sepal_len', y='sepal_wid', \n",
    "                s=100, data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# color by species\n",
    "sns.scatterplot(x='sepal_len', y='sepal_wid', hue='species', \n",
    "                s=100, data=df)\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- A) setosa and versicolor\n",
    "- B) setosa and virginica\n",
    "- C) versicolor and viginica\n",
    "- D) all quite distinct\n",
    "- E) all equally similar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![iris](img/iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PCA: Iris\n",
    "\n",
    "- define predictors\n",
    "- standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# split data table into predictors and outcome (class labels - species)\n",
    "iris_predictors = df.iloc[:,0:4].values\n",
    "iris_species = df.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Calculating PCs\n",
    "\n",
    "There are many ways to calculate PCs. You can calculate the covariance matrix and run eigendecomposition on that. You can use `SVD` (singular variable decomposition) from `numpy`. But, the simplest way to calculate PCs is from `sklearn`, using `PCA` (as seen above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# calculate PCs\n",
    "pca = PCA(n_components=4)\n",
    "iris_pca_fit = pca.fit(iris_predictors)\n",
    "iris_PCs = pca.fit_transform(iris_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# See PCs\n",
    "print(iris_pca_fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Selecting PCs\n",
    "\n",
    "The eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data; those are the ones can be dropped.\n",
    "\n",
    "In order to do so, the common approach is to rank the eigenvalues from highest to lowest in order choose the top ð‘˜ eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(iris_pca_fit.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(iris_pca_fit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "var_exp = pd.DataFrame(iris_pca_fit.explained_variance_ratio_,\n",
    "                       ['PC1', 'PC2','PC3','PC4'])\n",
    "var_exp.plot.bar(rot=0)\n",
    "plt.ylabel('variance explained');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "PC1 explains 92% of the variance.\n",
    "PC2 contains important information (5% of the variance).\n",
    "\n",
    "PCs 3 and 4 can safely be dropped without losing to much information. \n",
    "\n",
    "Together, the first two  PCs contain 97% of the information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe with PCs and label\n",
    "pca_out = pd.DataFrame(iris_PCs, \n",
    "                       columns=['PC1','PC2','PC3','PC4'])\n",
    "pca_out['species'] = df['species']\n",
    "pca_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# plot PC1 and PC2\n",
    "# color by species \n",
    "sns.scatterplot(x='PC1', y='PC2', hue='species', \n",
    "                s=100, data=pca_out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- A) setosa and versicolor\n",
    "- B) setosa and virginica\n",
    "- C) versicolor and viginica\n",
    "- D) all quite distinct\n",
    "- E) all equally similar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Iris: Summary\n",
    "\n",
    "While we're only looking at 4 variables here and PCA can handle many more quantitative information, we quickly get a  understanding of the overall structure of the data across all four quantitative variables using PCA within the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S&P 500 Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read data in\n",
    "sp = pd.read_csv('https://raw.githubusercontent.com/shanellis/datasets/master/sp500_data.csv')\n",
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Specify subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "funds = ['AAPL', 'AXP', 'COP', 'COST', 'CSCO', 'CVX', 'HD', \n",
    "        'INTC', 'JPM', 'MSFT', 'SLB', 'TGT', 'USB', \n",
    "        'WFC', 'WMT', 'XOM']\n",
    "\n",
    "sp = sp.loc[:,funds].transpose()\n",
    "sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Calculate PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# calculate PCs\n",
    "pca = PCA(n_components=5)\n",
    "sp_pca_fit = pca.fit(sp)\n",
    "sp_PCs = pca.fit_transform(sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Screeplot & Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# screeplot for first 5 PCs\n",
    "var_exp = pd.DataFrame(sp_pca_fit.explained_variance_ratio_,\n",
    "                       ['PC1', 'PC2','PC3','PC4', 'PC5'])\n",
    "var_exp.plot.bar(rot=0)\n",
    "plt.ylabel('variance explained');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe with PCs and label\n",
    "sp_out = pd.DataFrame(sp_PCs,\n",
    "                      columns=['PC1','PC2','PC3','PC4','PC5'],\n",
    "                      index=sp.index)\n",
    "\n",
    "sns.scatterplot(x = 'PC1', y ='PC2', \n",
    "                s = 300, data = sp_out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sp_out[sp_out['PC1'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- COP : ConocoPhillips (crude oil & natural gas)\n",
    "- CVX : Chevron\n",
    "- SLB : Schlumberger (technology for oil drilling)\n",
    "- XOM : Exxon Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe with PCs and label\n",
    "sp_out = pd.DataFrame(sp_PCs,\n",
    "                      columns=['PC1','PC2','PC3','PC4','PC5'],\n",
    "                      index=sp.index)\n",
    "\n",
    "pd.plotting.scatter_matrix(sp_out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PCA Summary\n",
    "\n",
    "- helpful to understand _many_ quantitative variables at a time\n",
    "- PCA helpful for understanding 'global' structure within dataset\n",
    "    - Identify outliers and groups (means that PCs will be driven by outliers)\n",
    "- Useful in EDA, modeling, & prediction\n",
    "- PCA from `sklearn` most straightforward approach to computation"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
